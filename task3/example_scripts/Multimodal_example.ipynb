{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Noik9q9c7Bhm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# [Task 2C: Multimodal Propagandistic Memes Classification](https://araieval.gitlab.io/task2/) at [ArabicNLP 2024](https://arabicnlp2024.sigarab.org/) @ACL 2024\n",
    "\n",
    "@Author: Md. Arid Hasan\n",
    "\n",
    "Given multimodal content (text extracted from meme and the meme itself) the task is to detect whether the content is propagandistic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYZ96DWt-TZk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### installing required libraries.\n",
    " - transformers\n",
    " - datasets\n",
    " - evaluate\n",
    " - accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SLJh5GGU-xET",
    "outputId": "b6520066-6946-4030-d523-892082c132d1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "!pip install --upgrade accelerate\n",
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-_w4YehCgX4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setting up the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lemacEHujmj4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate=2e-5\n",
    "num_train_epochs=2\n",
    "train_max_seq_len = 512\n",
    "max_train_samples = None\n",
    "max_eval_samples=None\n",
    "max_predict_samples=None\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXhVWUJ3A_hx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Define custom dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIUAU0rRBOmR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, AutoTokenizer\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, ids, text_data, image_data, labels, is_test=False):\n",
    "        self.text_data = text_data\n",
    "        self.image_data = image_data\n",
    "        self.ids = ids\n",
    "        self.is_test = is_test\n",
    "        #if not self.is_test:\n",
    "        self.labels = labels\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('distilbert-base-multilingual-cased') #bert-base-multilingual-uncased\n",
    "        self.transform = transforms.Compose([transforms.Resize(256),\n",
    "                                             transforms.CenterCrop(224),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                                             ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        id = self.ids[index]\n",
    "        text = self.text_data[index]\n",
    "        image = self.image_data[index]\n",
    "        #if not self.is_test:\n",
    "        label = self.labels[index]\n",
    "\n",
    "        # tokenize text data\n",
    "        text = self.tokenizer.encode_plus(text, add_special_tokens=True,\n",
    "                                           max_length=train_max_seq_len, padding='max_length',\n",
    "                                           return_attention_mask=True, return_tensors='pt')\n",
    "\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        image = self.transform(Image.open(image).convert(\"RGB\"))\n",
    "\n",
    "        fdata = {\n",
    "            'id': id,\n",
    "            'text': text['input_ids'].squeeze(0),\n",
    "            'text_mask': text['attention_mask'].squeeze(0),\n",
    "            'img_path': image,\n",
    "        }\n",
    "        if not self.is_test:\n",
    "            fdata['label'] = torch.tensor(label, dtype=torch.long)\n",
    "            return fdata\n",
    "        else:\n",
    "            return fdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HP6CdL7NHpxJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Download data from HF: https://huggingface.co/datasets/QCRI/Prop2Hate-Meme\n",
    "### Defining the training, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "5d1f1ce8b5df4419a18c8ad648998064",
      "22d0c9f4eb0d4f42a74764b3dfb20545",
      "bc21e2a523214725a2691405a3b1fbbd",
      "8bb6eb7dfc964182a65a76e1378710e7",
      "5be9de19b5ac4925bbb0d0985332a5f8",
      "0420dad7752f4a1c95fd90cbaf23f9bd",
      "8147eb3b9f244fbd9608105325b5e35f",
      "29c9bd1943d54c91af9ab3609d1fc416",
      "409a40649f384a6ea402b7fedd262cd0",
      "c8d25da0b3d04504b5e85a5fb6695c10",
      "b049099cfa0247b1979b7e91edea3eb3",
      "47d84c7c2080480a8536b3b66904b191",
      "a4cb6928d3394b01874d2f607b68dc01",
      "e778e84a6f87474c85900e3b4602837e",
      "7b221543eecb4050983941ef833ffa7b",
      "5ade255d0f6b44fa852f5a87a5b17947",
      "545c5c66fcfa43a5b93fb2320cea6550",
      "3138d0180f454a1e97674d29628c9024",
      "fcca176a6f21409d963b8863b2fd2da1",
      "c62db90501354f7fa0df1d0ad538d0cd",
      "39cd8f7719324047868db4b4c429390d",
      "e3c923e3ec46446bbde0973a62c11819",
      "9a63e319aec644daadf77ac169acfe4d",
      "8ab5c07ef99d4987a24f40da6daa32ac",
      "c4cc04a0f5d342309fa9abc2e063d0bb",
      "310dd31d4197455c8ff494db8f37d03a",
      "511d7e40069b4adfacde110b7efcc65b",
      "429557382fab4cfbbfaa9ef3c5d9a479",
      "bfb6ae0ab8c14854a54f14c9a9302f09",
      "7e4edda7e344435793d48989a4003c70",
      "7f0dd68ea8d447e4b4d62aff724de9e0",
      "954bfb431f0c43beac2918bbbeb111fe",
      "c00312da61464a7ab31cfa3d2746df80"
     ]
    },
    "id": "KBe3fs9uarvU",
    "outputId": "54c08f6c-f7af-41dc-9959-6b0dde2a0385"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"QCRI/Prop2Hate-Meme\")\n",
    "\n",
    "# Specify the directory where you want to save the dataset\n",
    "\n",
    "output_dir=\"./Prop2Hate-Meme\"\n",
    "\n",
    "# Save the dataset to the specified directory. This will save all splits to the output directory.\n",
    "dataset.save_to_disk(output_dir)\n",
    "\n",
    "# If you want to get the raw images from HF dataset format\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Directory to save the images\n",
    "output_dir=\"./Prop2Hate-Meme/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over the dataset and save each image\n",
    "for split in ['train','dev','test']:\n",
    "    jsonl_path = os.path.join(output_dir, f\"arabic_hateful_meme_{split}.jsonl\")\n",
    "    with open(jsonl_path, 'w', encoding='utf-8') as f:\n",
    "        for idx, item in enumerate(dataset[split]):\n",
    "            # Access the image directly as it's already a PIL.Image object\n",
    "            image = item['image']\n",
    "            image_path = os.path.join(output_dir, item['img_path'])\n",
    "            # Ensure the directory exists\n",
    "            os.makedirs(os.path.dirname(image_path), exist_ok=True)\n",
    "            image.save(image_path)\n",
    "            del item['image']\n",
    "            del item['prop_label']\n",
    "            del item['hate_fine_grained_label']\n",
    "            item['label'] = item.pop('hate_label')\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMzfE34iHyGV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"Prop2Hate-Meme\")\n",
    "\n",
    "train_file = './arabic_hateful_meme_train.jsonl'\n",
    "validation_file = './arabic_hateful_meme_dev.jsonl'\n",
    "test_file = './arabic_hateful_meme_test.jsonl'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAV7v54pdm-T",
    "outputId": "2eb50484-6c38-42ae-f541-75c7b362ee47"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqCBQCIWdykt",
    "outputId": "0aab59ab-a9e4-48f5-8e6b-db45716540c6"
   },
   "outputs": [],
   "source": [
    "jsonl_path = \"./arabic_hateful_meme_train.jsonl\" # Example path, modify as needed\n",
    "data = []\n",
    "with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "  for line in f:\n",
    "    data.append(json.loads(line))\n",
    "\n",
    "# data is now a list of dictionaries, where each dictionary is a parsed JSON object from a line in the file.\n",
    "print(f\"Loaded {len(data)} entries from {jsonl_path}\")\n",
    "if data:\n",
    "    print(\"First entry:\")\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgkvwlbFHVo5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-De1tz5qHYre",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text_model_name = 'distilbert-base-multilingual-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgNrs7AhKdvl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Loading data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDwaW8AnKcgD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def read_jsonl_to_df(filename):\n",
    "    return pd.read_json(filename, lines=True)\n",
    "\n",
    "l2id = {'not-hateful': 0, 'hateful': 1}\n",
    "\n",
    "# Assume all splits use \"img_path\" as the image column\n",
    "def prepare_dataset(file):\n",
    "    df = read_jsonl_to_df(file)\n",
    "    # df['label'] = df['label'].map(l2id)\n",
    "    # Cast \"img_path\" column as Image\n",
    "    return Dataset.from_pandas(df) #.cast_column(\"img_path\", Image())\n",
    "\n",
    "train_df = prepare_dataset(train_file)\n",
    "train_dataset = MultimodalDataset(train_df['id'], train_df['text'], train_df['img_path'], train_df['label'])\n",
    "\n",
    "validation_dataset = prepare_dataset(validation_file)\n",
    "validation_dataset = MultimodalDataset(validation_dataset['id'], validation_dataset['text'], validation_dataset['img_path'], validation_dataset['label'])\n",
    "\n",
    "test_dataset = prepare_dataset(test_file)\n",
    "test_dataset = MultimodalDataset(test_dataset['id'], test_dataset['text'], test_dataset['img_path'], test_dataset['label'])\n",
    "\n",
    "raw_datasets = DatasetDict(\n",
    "    {\"train\": train_dataset, \"validation\": validation_dataset, \"test\": test_dataset}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-yDKlycyoZA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Finalize the train data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjfGaFbqdxpj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwSFrRg4mNRh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if max_train_samples is not None:\n",
    "    max_train_samples_n = min(len(train_dataset), max_train_samples)\n",
    "    train_dataset = train_dataset.select(range(max_train_samples_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k72vUTSigOzZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Finalize the development/evaluation data for evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MqrW8ospgUYZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if max_eval_samples is not None:\n",
    "    max_eval_samples_n = min(len(validation_dataset), max_eval_samples)\n",
    "    validation_dataset = validation_dataset.select(range(max_eval_samples_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7sVqp3hgU4i",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Finalize the test data for predicting the unseen test data using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0dBjIQggcYs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if max_predict_samples is not None:\n",
    "    max_predict_samples_n = min(len(test_dataset), max_predict_samples)\n",
    "    test_dataset = test_dataset.select(range(max_predict_samples_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cqbo1xzRge36",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Log a few random samples from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wIO2bxSVgkLb",
    "outputId": "997ceec2-b658-4501-8d29-b5ef5065922a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "for index in random.sample(range(len(train_dataset)), 2):\n",
    "    print(f\"Sample {index} of the training set: {train_dataset[index]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFh6wO9CuheP",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Batchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZBwbR0Aq0Fq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "validation_df = torch.utils.data.DataLoader(validation_dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "test_df = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbhskCcnNYYT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## MultiModal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GAkUKbHFNci_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from transformers import BertModel, AutoModel\n",
    "\n",
    "# Define the multimodal classification model\n",
    "class MultimodalClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultimodalClassifier, self).__init__()\n",
    "\n",
    "        # BERT model for text input\n",
    "        #config = AutoConfig.from_pretrained('xlm-roberta-xlarge', num_labels=2,use_auth_token=None)\n",
    "        self.bert = AutoModel.from_pretrained(text_model_name)\n",
    "\n",
    "        self.bert_drop = nn.Dropout(0.3)\n",
    "        self.bert_fc = nn.Linear(768, 512) #for BERT=768\n",
    "\n",
    "        # ResNet model for image input\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet_fc = nn.Linear(1000, 512)\n",
    "\n",
    "        # Fusion layer\n",
    "        self.fusion_fc = nn.Linear(1024, 512)\n",
    "        # Output layer\n",
    "        self.output_fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, text, image, mask):\n",
    "        #image = image.unsqueeze(0)\n",
    "        # Text input through BERT model\n",
    "        bert_output = self.bert(text, attention_mask=mask, return_dict=False) #attention_mask=mask,\n",
    "        #bert_output = self.bert(text, attention_mask=mask, return_dict=False) #attention_mask=mask,\n",
    "        #print(bert_output)\n",
    "        bert_output = self.bert_drop(bert_output[0][:, -1, :])\n",
    "        bert_output = self.bert_fc(bert_output)\n",
    "\n",
    "\n",
    "        # Image input through ResNet model\n",
    "        resnet_output = self.resnet(image)\n",
    "        resnet_output = self.resnet_fc(resnet_output)\n",
    "\n",
    "        # Concatenate the text and image features\n",
    "        # bert_output = bert_output.squeeze(2)\n",
    "        # print(bert_output.shape)\n",
    "        # print(resnet_output.shape)\n",
    "        features = torch.cat((bert_output, resnet_output), dim=1)\n",
    "\n",
    "        # Fusion layer\n",
    "        features = self.fusion_fc(features)\n",
    "        # Output layer\n",
    "        output = self.output_fc(features)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Define the training and testing functions\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    for data in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        text = data[\"text\"].to(device)\n",
    "        #print(text.shape)\n",
    "        image = data[\"img_path\"].to(device)\n",
    "        mask = data[\"text_mask\"].to(device)\n",
    "        #print(mask.shape)\n",
    "        labels = data['label'].to(device)\n",
    "        output = model(text, image, mask)\n",
    "        #print(output)\n",
    "        loss = criterion(output, labels)\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * labels.size(0)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    accuracy = correct / len(train_loader.dataset)\n",
    "    return train_loss, accuracy\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            text = data[\"text\"].to(device)\n",
    "            image = data[\"img_path\"].to(device)\n",
    "            mask = data[\"text_mask\"].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            output = model(text, image, mask)\n",
    "            loss = criterion(output, labels)\n",
    "            test_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return test_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afPkDvllPsnC",
    "outputId": "43c12bcd-4cbf-48bf-8994-c24821cb2c8a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultimodalClassifier(num_classes=2)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, acc = train(model, train_df, criterion, optimizer, device)\n",
    "    #dev_loss, accuracy = test(model, eval_dataset, criterion, device)\n",
    "    print('Epoch {}/{}: Train Loss = {:.4f}, Accuracy = {:.4f}'.format(epoch+1, num_epochs, train_loss, acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-teCIiNavdSJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8S3ctqRuvbQ-",
    "outputId": "b1ca709a-8f2c-4aef-bbc4-3d709bd12772",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    y_test_pred = []\n",
    "    ids = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            text = data[\"text\"].to(device)\n",
    "            image = data[\"img_path\"].to(device)\n",
    "            mask = data[\"text_mask\"].to(device)\n",
    "            output = model(text, image, mask)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            predictions.append(predicted)\n",
    "            ids.append(data[\"id\"])\n",
    "\n",
    "    with open(f'task2_TeamName.tsv', 'w') as f:\n",
    "      f.write(\"id\\tlabel\\n\")\n",
    "      indx = 0\n",
    "      id2l = {0:'not-hateful', 1:'hateful'}\n",
    "      for i, line in enumerate(predictions):\n",
    "        for indx, l in enumerate(line.tolist()):\n",
    "          f.write(f\"{ids[i][indx]}\\t{id2l[l]}\\n\")\n",
    "\n",
    "evaluate(model, validation_df, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbSWop7viib9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
