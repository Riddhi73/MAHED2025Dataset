{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Noik9q9c7Bhm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# [Task 3: Multimodal Hate Speech Detection in Memes](https://github.com/marsadlab/MAHED2025Dataset/tree/main/task3/) at [ArabicNLP 2025](http://arabicnlp2025.sigarab.org/) @ACL 2025\n",
    "\n",
    "\n",
    "Given multimodal content (text extracted from meme and the meme itself) the task is to detect whether the content is hateful or not-hateful. This is a binary classification task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSxBhCps7oBf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYZ96DWt-TZk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### installing required libraries.\n",
    " - transformers\n",
    " - datasets\n",
    " - evaluate\n",
    " - accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLJh5GGU-xET",
    "outputId": "28edbaec-db44-4743-cbb7-393814e07c78",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "!pip install --upgrade accelerate\n",
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIm63PaZOI3V"
   },
   "source": [
    "## Download data from HF: https://huggingface.co/datasets/QCRI/Prop2Hate-Meme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627,
     "referenced_widgets": [
      "15fe42a8dbfb4b71b6979bea6620bfe9",
      "ad3026dd53634d5386c62f48544c2e6e",
      "4cefc8827019440c828c515fcf0177bf",
      "46df2802cbd941cd83b92083edded7dd",
      "bf4c77fe24f24779ad5f96a5158cd229",
      "03e586bca8954017adc862dab8176642",
      "ecf45b97b63a43bb9c5dc22bfa0f290d",
      "c5886f52ae2f40e1bc181eb2978b4cb0",
      "bdd1cb7f3af94600ab8a7bec2ad7d9b9",
      "8fbe5c5d5bb240a4927a72ae273b389f",
      "28ef1e5ba65a4c7d8791af36868bf796",
      "df20c3bbb73d487dbc9d64813ac69ab4",
      "837030562e364ef8a267bb7772b1a9de",
      "a5e522cfdf244ad69ab57f084758e89a",
      "56ddd4a899d84ea1a07a580f0687f85f",
      "48c36c34d1af4d5fa0bf5045c0b43e4c",
      "301f6a6393ea48159641623f479191ea",
      "f2bbd90a8bad48fd8424a9b33fd1f493",
      "8673508d94814050b0bb8e6dc698828d",
      "7c19571cffec4de999105c01081ee0a5",
      "0f54b91e80714d2bb6ed71d9ba62d35a",
      "ea599e88bf37479081e442be2678c81c",
      "addbbc45956c43b0a52efcca1bf14f6d",
      "8cafe8a91f4d4abbbf71ac5c7a184970",
      "6123676a5af1495886186816a393a666",
      "c6d73e1c6d4c4c9c9d0cbfb522aac532",
      "e8415760545042078385f79a63977605",
      "0cec3ce2c7374291856dece184850271",
      "4f3a44306302401ca0de460d969a5983",
      "ea55925a77034eb09432d9b846382a21",
      "b7bcc70b906341d487838e6613e9959e",
      "500999f055a04f9c985df87902ab528e",
      "e8edbe72196b402d84d2fc47035d6e87",
      "c4695addce884c5ba79b5acd375cca42",
      "f90c49ca708f4041b0c5718417cfaf77",
      "fa840047ba474ddc9bacdab9fe6fbbe6",
      "73f1e74718784e97ac5f414b1942d84b",
      "b5a7ce1548204625b0d079a986f9b1a7",
      "c4c008c36f5849178b7db72a2b9fa913",
      "40a07f52a4d84d5c98dc439e51b556d6",
      "88a7a21e7e67472088e333b5db68aabe",
      "a11d685a58ab4b43a8f3ee878c29d4da",
      "d76f3e14c701489799e6794bbe61a617",
      "7d4d8acd165a45ae995c71f5c32e5daa",
      "237b2a0b896246b284b074f47ff0f2c8",
      "1c73890895904cdaaed20148de30c585",
      "01cfb97f122d4cdfb8bb7691934665d1",
      "d6dfa6d5bd19413fba245affa670a87e",
      "6852375869b045978bf32cf474848469",
      "af126a5352824e28bc4dc50df65a7da6",
      "3b9e299354584bd68cd438e311a05bd4",
      "1c2445e1d62e4958b514a10a860855c2",
      "d220c3c3f1fa43aa9cad60628488ec66",
      "5673d691e0f8422ca8b5402b6032941b",
      "a2a8d03823384c20b930dbbc9f1cd521",
      "bb0f4d97585740bb9681ad7a743599c7",
      "658306584326472f85f0eabcb6462b62",
      "2ce905a1fcd24036aa38a65f92a73043",
      "0f85d343c3034d488cd08ddef12a55c6",
      "21c65f10b9ea4a798e44dc963c45d591",
      "908f6587daed4d6b871776cc13b4673e",
      "c3e1b60160e64db28ca4ac1575c5231a",
      "f7abf8e4cf914493a849d0f4c030df22",
      "2f1b8abf82574668bb685ecb91c4735f",
      "f4ff586be2bb4102b8db36b261edcfe8",
      "0e143f6d889b4c5a960e728c4745c13a",
      "068baa90d5224042b7260826dd72ddde",
      "306d2b2628574a29af673a27f24ab8fd",
      "385eae7543f44fc19dd89f79be423235",
      "9ae1c425621d4c16b896aac12ed5de21",
      "e94372d8fdf247739668bc62dd033341",
      "942598ced9c64a799c9eb29a783029a3",
      "1138afbaaf7d413f939e61082ca4b0c1",
      "3e7407aa40d249cbad7e94cd3129bf9a",
      "e99ad078e8914a248bcc184dc4fed1d3",
      "2ce48e9fe8fc44deb1a3d2713df36741",
      "965347a3e1dd43319489f62800bf8c9e",
      "d1dcdf164abf424ea7b685ee1b454432",
      "0f62c745044a44ac82264507df44fc2d",
      "97a92ad3781047d3a2d9c0bc83400519",
      "ac0546d8ae5148df8f0b0fc6ef2abbe4",
      "f156e145c6c84006992a509799d5d0dd",
      "21e8fb64e29b4fad8578c52a1c981d30",
      "ae2ebeb6c6ce41238743e82c7491ef7c",
      "7cb1db3943234bc091dffafc35b5681e",
      "6cbe8d922b32437e8abb85232d11ce0e",
      "d1d5cc5a9c0647cda1abe8e32d21738c",
      "35c877effcea4e43ade929f1a878bd38",
      "625c3b3c0d5d4807b65f631bf482e0ec",
      "4d0cbf025cea42e4a2ab3128839a2895",
      "55ec517c29104779b6afe9a6b99c0a24",
      "33d6317d878d43b9b87337185b23ca72",
      "8c968c4f3f5a46699b2ee25c6dfca684",
      "0b89cd350ffa4194b829ca37b2305b0f",
      "4721d33213204ce3b4f83250a8214734",
      "4a7a47e31e774d2d9d022c8d0ce20bd2",
      "a7d39559c0d44793be41cf5f7bed1a73",
      "62a7cc633e9d495680f10f9c5ae8c336",
      "73816682f53c409d98348a92838e7f6b",
      "43157a51b3354b92b0fc84f47868d338",
      "55b166b943cc45dca018072097006c0a",
      "b8316bce7cca42e592dd001d162e1f4e",
      "7eaeebab2d5c487a98194e34387c2a81",
      "b63cea42b5b5449aab10cfa614b0ffc7",
      "56d8260a52ee4f2f812b4b5806624c67",
      "c532e84b7054495aa2c6c2a901741b3e",
      "05d5d9f2d0e34c79bbe427b50c183fcc",
      "d8693158cba54ff782f60f5a5f38f525",
      "133a6532e8a748d9a291008f6b6d3368",
      "c939ff7744c341c39c9a45e9df6bff1a"
     ]
    },
    "id": "BvwQNYHk6kV5",
    "outputId": "78758a7a-9c91-4cac-c312-24472cd15c3e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"QCRI/Prop2Hate-Meme\")\n",
    "\n",
    "# Specify the directory where you want to save the dataset\n",
    "\n",
    "output_dir=\"./Prop2Hate-Meme\"\n",
    "\n",
    "# Save the dataset to the specified directory. This will save all splits to the output directory.\n",
    "dataset.save_to_disk(output_dir)\n",
    "\n",
    "# If you want to get the raw images from HF dataset format\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Directory to save the images\n",
    "output_dir=\"./Prop2Hate-Meme/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over the dataset and save each image\n",
    "for split in ['train','dev','test']:\n",
    "    jsonl_path = os.path.join(output_dir, f\"arabic_hateful_meme_{split}.jsonl\")\n",
    "    with open(jsonl_path, 'w', encoding='utf-8') as f:\n",
    "        for idx, item in enumerate(dataset[split]):\n",
    "            # Access the image directly as it's already a PIL.Image object\n",
    "            image = item['image']\n",
    "            image_path = os.path.join(output_dir, item['img_path'])\n",
    "            # Ensure the directory exists\n",
    "            os.makedirs(os.path.dirname(image_path), exist_ok=True)\n",
    "            image.save(image_path)\n",
    "            del item['image']\n",
    "            del item['prop_label']\n",
    "            del item['hate_fine_grained_label']\n",
    "            item['label'] = item.pop('hate_label')\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWNf8ynBP3tJ",
    "outputId": "73c0807f-0652-4112-8bba-971c2d35ab37"
   },
   "outputs": [],
   "source": [
    "jsonl_path = \"./Prop2Hate-Meme/arabic_hateful_meme_train.jsonl\" # Example path, modify as needed\n",
    "data = []\n",
    "with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "  for line in f:\n",
    "    data.append(json.loads(line))\n",
    "\n",
    "# data is now a list of dictionaries, where each dictionary is a parsed JSON object from a line in the file.\n",
    "print(f\"Loaded {len(data)} entries from {jsonl_path}\")\n",
    "if data:\n",
    "    print(\"First entry:\")\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JY8zBK4bQvNZ"
   },
   "source": [
    "### Defining the training, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8NnFuC1QrEw"
   },
   "outputs": [],
   "source": [
    "train_file = './Prop2Hate-Meme/arabic_hateful_meme_train.jsonl'\n",
    "validation_file = './Prop2Hate-Meme/arabic_hateful_meme_dev.jsonl'\n",
    "test_file = './Prop2Hate-Meme/arabic_hateful_meme_test.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXhVWUJ3A_hx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIUAU0rRBOmR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HP6CdL7NHpxJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMzfE34iHyGV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-_w4YehCgX4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setting up the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-GUUNj0BPbu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    output_dir=\"./distilBERT_m/\",\n",
    "    overwrite_output_dir=True,\n",
    "    remove_unused_columns=False,\n",
    "    local_rank= 1,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"no\"\n",
    ")\n",
    "\n",
    "max_train_samples = None\n",
    "max_eval_samples=None\n",
    "max_predict_samples=None\n",
    "max_seq_length = 512\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Q4deAnUJ0iI",
    "outputId": "d9fe1e33-3872-4f33-91c0-bf60d4bf579a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformers.utils.logging.set_verbosity_info()\n",
    "\n",
    "log_level = training_args.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\" distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "# logger.info(f\"Training/evaluation parameters {training_args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgkvwlbFHVo5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-De1tz5qHYre",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-multilingual-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPqrrDbcKN8n",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### setting the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZvKpoxaQKTB6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgNrs7AhKdvl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Loading data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDwaW8AnKcgD",
    "outputId": "419ca945-775a-40e2-a2f5-15c964eb5b35",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "## label 0 -> not-hate, 1 -> hate\n",
    "def read_jsonl_to_df(filename):\n",
    "    return pd.read_json(filename, lines=True)\n",
    "\n",
    "\n",
    "l2id = {'not-hate': 0, 'hate': 1}\n",
    "\n",
    "train_df = read_jsonl_to_df(train_file)\n",
    "# train_df['label'] = train_df['label'].map(l2id)\n",
    "train_df = Dataset.from_pandas(train_df)\n",
    "validation_df = read_jsonl_to_df(validation_file)\n",
    "# validation_df['label'] = validation_df['label'].map(l2id)\n",
    "validation_df = Dataset.from_pandas(validation_df)\n",
    "test_df = read_jsonl_to_df(test_file)\n",
    "# test_df['label'] = test_df['label'].map(l2id)\n",
    "test_df = Dataset.from_pandas(test_df)\n",
    "\n",
    "\n",
    "\n",
    "data_files = {\"train\": train_df, \"validation\": validation_df, \"test\": validation_df}\n",
    "\n",
    "for key in data_files.keys():\n",
    "    logger.info(f\"loading a local file for {key}\")\n",
    "raw_datasets = DatasetDict(\n",
    "    {\"train\": train_df, \"validation\": validation_df, \"test\": test_df}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJhNu7tPQ2RU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Extracting number of unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTl6NNPmOXhO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Labels\n",
    "label_list = raw_datasets[\"train\"].unique(\"label\")\n",
    "label_list.sort()  # sort the labels for determine\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1dpoOAPRJnN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading Pretrained Configuration, Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fe3667c54105447b886de160fa1f69a1",
      "a866f6a1cbff47a1adc0fa28aa73cfc4",
      "f00529a498bb4d6c8cc9f6e34d0acdca",
      "c179a7538f5a4915bfd4628d032e76e3",
      "d2926b1b407447698398895899c03eeb",
      "3df16bff17ca4957bced1c64071c300a",
      "4e0c964988454be1bd91925acb66033e",
      "c2160419b4a64c69ace0c72c4da5aa3a",
      "107570197f654baebaa4456b3b0eec7b",
      "468267a0168a4eea9bee9f0a005523aa",
      "656e429b49984671bd69536e25c22709",
      "5f209a48fd764a439ffbef0e4ca414ec",
      "e070e34f3d7c4c76be0ca34603917697",
      "a794616a61ed46f39a29109d2012e2f8",
      "9cdefa91eaef474b9b9e478a8cb9fd48",
      "4b56f0a9e6f24a5abd263418f0cdd9ee",
      "c40fbbb3624a4de7b4f8d7fb77c027b0",
      "45ded88483b342609f55c4e8897a71b2",
      "4ffccb3781a047f9801ef0e5e2029afc",
      "4909114e73fe4476b6570614f110ed6f",
      "962bcd38ea024a0ab0ae7f83e65d4bb5",
      "8118347a6211453690fdcd39e6b11c6c",
      "4d22576e956a442d8aaf4a7fe8fc99ee",
      "8bef7423793b4c42badb72f046deb517",
      "da68d68399174512b8775742b9170ca0",
      "76ca9b47142b47d89c1bda2f81cc2430",
      "568caf3a26384d38aded346bbc2ef6eb",
      "60c03a32d09849a98c7b387db46fce3f",
      "c05e360a517b48b9af3f7634d6401b4c",
      "fa4245ecaafc431b991743777a703928",
      "fc28f778ac8c4eada63b27eaf28ed891",
      "0d39999c33034692a93111043017efc0",
      "dc7415fd3d814ecebbd0c45560307f4f",
      "a4ec18c4bbca4f5688500f73c7741154",
      "cd43f6b695f64439ab640e73213cc5ac",
      "3931966b0404407fa46448e500c99cbd",
      "0c60015a6c324c1091f292994b37e11b",
      "fcb71867b75146448558ad7168911651",
      "c86176066fa1436b8b9dccd16bc10f10",
      "f5b54b9b958748738d5036371ec27104",
      "ccfbe74888d24543bcbed80677cb4c69",
      "82119bed2bf645a6b54dbcd18488f154",
      "8092135ef8dc4a9aa867f45d0e0898b1",
      "c401f0488c7645ac80f8e7029c674e18",
      "d0c74553d25c44d28520e9602b6bb0d6",
      "5aee549a53e7471a8367716e3c4e5b55",
      "af25ba0543684bfe8c8ace7bbc622a79",
      "7823d7539c2548849fff12d7d9a52087",
      "2dd76897be8741d586d98137b4289684",
      "5fd4780854924a5faca6253581e3532d",
      "8f989d2b81064c0e920032d7abbe9955",
      "94f9b6a00273455898a9bd852e0113d2",
      "6e8add94f43f4282bbd88282a3241ca8",
      "1c735acbfae746b38e9521855906be76",
      "498c4fe39b3c4b3bb6966faa47ad1063"
     ]
    },
    "id": "jmAaMuBuRQd2",
    "outputId": "b323ee82-31ad-4cc2-c339-788efa034cda",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    finetuning_task=None,\n",
    "    cache_dir=None,\n",
    "    revision=\"main\",\n",
    "    use_auth_token=None,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=None,\n",
    "    use_fast=True,\n",
    "    revision=\"main\",\n",
    "    use_auth_token=None,\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    from_tf=bool(\".ckpt\" in model_name),\n",
    "    config=config,\n",
    "    cache_dir=None,\n",
    "    revision=\"main\",\n",
    "    use_auth_token=None,\n",
    "    ignore_mismatched_sizes=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7PIQVypeTf4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Preprocessing the raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141,
     "referenced_widgets": [
      "476d864bd0c74ffbbcf5bcb28a1273c2",
      "dd483ce504d04821929f46eaf07f0a1f",
      "cffafed4000d484996eeab8ce319b271",
      "e78067a78d2d49fbba23397076a5d709",
      "f99f2a95384b430393c6aa7ac842e003",
      "434d4c0415764ada9371faed4944a25e",
      "3f851cde09584324a0858a6eaa2a8b09",
      "b72525c7e88f41529e3573e137d040d8",
      "d07529ae77f448679ff53b3bc3f8f85a",
      "47bbe6245066406893ed6e2802361356",
      "ffc16c4262ea4cbc8bfdfb31322e2370",
      "f92a9c3cedac46c588220d09b4cd5eec",
      "1970d0e61e7e480d8bfa335bc579ba73",
      "005625fae5b243f6ab9d8eda54638e6c",
      "9c387bb1a3df4e27a553670dcb0c7f29",
      "b33764f066784bc19fc270a2ffb5cba0",
      "fc77c9cde8f84767883bd14108c0f270",
      "dd6701d3c13640d69aab68b2929b81ac",
      "d0275ee8b82f4f3ca961a8d7f7d2c23f",
      "ea5b0807421240d4bf35d625be59ebfd",
      "cd49e52e8c284dffadeff078a380260a",
      "826ef49a4afa40b19e41b11ec319e1c6",
      "200206d71746423496ea25b0bf9f14bf",
      "694bebecf9e44010a727efc0828ea82f",
      "8dc29024edce4d3a95e2558f1e5b9ca7",
      "e3d496940f84462da1229188a7ad8554",
      "a1f8e25436064941ba289b206ba74af1",
      "e85c37a7527b4d3b95c5fdee2366b0e3",
      "483506e24be34705b4ef14c8cd084297",
      "7d6ab67408dd44648aee2a8a0fe02f41",
      "9ce925667ad54c4b80460d9449a966d0",
      "373a763d9ef94da8bccb544868099dd2",
      "e549ece6f9094b22b827a3be7376ac83"
     ]
    },
    "id": "pqO3YWAZelhd",
    "outputId": "d7187666-6887-4494-8809-d8dc39d82c72",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "non_label_column_names = [name for name in raw_datasets[\"train\"].column_names if name != \"label\"]\n",
    "sentence1_key= non_label_column_names[1]\n",
    "\n",
    "# Padding strategy\n",
    "padding = \"max_length\"\n",
    "\n",
    "# Some models have set the order of the labels to use, so let's make sure we do use it.\n",
    "label_to_id = None\n",
    "if (model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id):\n",
    "    # Some have all caps in their config, some don't.\n",
    "    label_name_to_id = {k.lower(): v for k, v in model.config.label2id.items()}\n",
    "    if sorted(label_name_to_id.keys()) == sorted(label_list):\n",
    "        label_to_id = {i: int(label_name_to_id[label_list[i]]) for i in range(num_labels)}\n",
    "    else:\n",
    "        logger.warning(\n",
    "            \"Your model seems to have been trained with labels, but they don't match the dataset: \",\n",
    "            f\"model labels: {sorted(label_name_to_id.keys())}, dataset labels: {sorted(label_list)}.\"\n",
    "            \"\\nIgnoring the model labels as a result.\",)\n",
    "\n",
    "if label_to_id is not None:\n",
    "    model.config.label2id = label_to_id\n",
    "    model.config.id2label = {id: label for label, id in config.label2id.items()}\n",
    "\n",
    "if 128 > tokenizer.model_max_length:\n",
    "    logger.warning(\n",
    "        f\"The max_seq_length passed ({128}) is larger than the maximum length for the\"\n",
    "        f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\")\n",
    "max_seq_length = min(128, tokenizer.model_max_length)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    args = (\n",
    "        (examples[sentence1_key],))\n",
    "    result = tokenizer(*args, padding=padding, max_length=max_seq_length, truncation=True)\n",
    "\n",
    "    # Map labels to IDs (not necessary for GLUE tasks)\n",
    "    if label_to_id is not None and \"label\" in examples:\n",
    "        result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
    "    return result\n",
    "raw_datasets = raw_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASxWKiqifb_g",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Finalize the training data for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHoDqrBGgD6F",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if \"train\" not in raw_datasets:\n",
    "    raise ValueError(\"requires a train dataset\")\n",
    "train_dataset = raw_datasets[\"train\"]\n",
    "if max_train_samples is not None:\n",
    "    max_train_samples_n = min(len(train_dataset), max_train_samples)\n",
    "    train_dataset = train_dataset.select(range(max_train_samples_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqME25nm-hwo",
    "outputId": "7cfb0d21-6c13-45df-cd53-b4693714882c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k72vUTSigOzZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Finalize the development/evaluation data for evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MqrW8ospgUYZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if \"validation\" not in raw_datasets:\n",
    "    raise ValueError(\"requires a validation dataset\")\n",
    "eval_dataset = raw_datasets[\"validation\"]\n",
    "if max_eval_samples is not None:\n",
    "    max_eval_samples_n = min(len(eval_dataset), max_eval_samples)\n",
    "    eval_dataset = eval_dataset.select(range(max_eval_samples_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7sVqp3hgU4i",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Finalize the test data for predicting the unseen test data using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0dBjIQggcYs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if \"test\" not in raw_datasets and \"test_matched\" not in raw_datasets:\n",
    "    raise ValueError(\"requires a test dataset\")\n",
    "predict_dataset = raw_datasets[\"test\"]\n",
    "if max_predict_samples is not None:\n",
    "    max_predict_samples_n = min(len(predict_dataset), max_predict_samples)\n",
    "    predict_dataset = predict_dataset.select(range(max_predict_samples_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cqbo1xzRge36",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Log a few random samples from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wIO2bxSVgkLb",
    "outputId": "b8e17fdd-4e2f-49b0-a8a4-5d1e89eb43df",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for index in random.sample(range(len(train_dataset)), 3):\n",
    "    logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAcn0Pc8gogF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Get the metric function `accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "21e69f2a99414fefa9df9c1416402793",
      "9b26f5a208a942a086df5863e3a5febe",
      "0b2678b7674d401aab3680eba17461ea",
      "846babfe950a4431bee574f522a755e7",
      "a15bbbf1ee3f42c48f593576a7ec13c5",
      "38ca4a95f941425d8b01fc111f44c79d",
      "a168079286ea4997b4ef007c8278d623",
      "11522e53e07b4e2fa69076e948927930",
      "693492cd9ad44222b0f711e47bc1c221",
      "ec22723931d742f1b6266230c526ef76",
      "c19d845057d04747927e4b6cc95b2292"
     ]
    },
    "id": "aMWMQdaUgvAq",
    "outputId": "eebbe45c-86ed-4bfe-fb69-a513746773a0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foWUyuBHgxbA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Predictions and label_ids field and has to return a dictionary string to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3VqxkqcgxCC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNWK1Hfbg8-o",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_w6lNh-OhJLC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nYlugPRhNbg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Initialize our Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeJco0JOhPHx",
    "outputId": "ce761897-8aa3-4065-b05c-e08d902c490f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    # eval_dataset=eval_dataset, # if you have development and test set, uncomment this line\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUxWn9HrhqRM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "B681qnPFhtY0",
    "outputId": "ab457ec0-9c51-4416-d6c7-63ebab4e38f5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics\n",
    "max_train_samples = (\n",
    "    max_train_samples if max_train_samples is not None else len(train_dataset)\n",
    ")\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaaRglkwllSp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Saving the tokenizer too for easy upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9UwoMEbAloMx",
    "outputId": "3e3dc2c1-6c47-4042-d13d-beb4e5761319",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9zCKBGEhwb7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Evaluating our model on validation/development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "YClw3dXTh17u",
    "outputId": "7eb26a1e-1797-4a13-e0d3-6b9ec6d84c0d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"*** Evaluate ***\")\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "\n",
    "max_eval_samples = (\n",
    "    max_eval_samples if max_eval_samples is not None else len(eval_dataset)\n",
    ")\n",
    "metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
    "\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3LSdUdPh7uG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Predecting the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71INKaEmU6lS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# if the test set is available, you don't need to run this cell\n",
    "# predict_dataset = eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "gnXhVq6Yh_oS",
    "outputId": "6063a0ee-51ed-4487-a575-289a74537387",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "id2l = {0:'not-hate', 1:'hate'}\n",
    "logger.info(\"*** Predict ***\")\n",
    "#predict_dataset = predict_dataset.remove_columns(\"label\")\n",
    "ids = predict_dataset['id']\n",
    "predict_dataset = predict_dataset.remove_columns(\"id\")\n",
    "predictions = trainer.predict(predict_dataset, metric_key_prefix=\"predict\").predictions\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "output_predict_file = os.path.join(training_args.output_dir, f\"task3_TeamName.csv\")\n",
    "if trainer.is_world_process_zero():\n",
    "    with open(output_predict_file, \"w\") as writer:\n",
    "        logger.info(f\"***** Predict results *****\")\n",
    "        writer.write(\"id\\tprediction\\n\")\n",
    "        for index, item in enumerate(predictions):\n",
    "            item = label_list[item]\n",
    "            item = id2l[item]\n",
    "            writer.write(f\"{ids[index]}\\t{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "8Gqqk_24__47",
    "outputId": "af9d07ca-70a9-466b-e317-bea7acd66610",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQgoTTIoiI0X",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Saving the model into card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1ooJgrViLVj",
    "outputId": "750f9d73-04a5-44a9-a98d-eaf344fa8c66",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kwargs = {\"finetuned_from\": model_name, \"tasks\": \"text-classification\"}\n",
    "trainer.create_model_card(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDcmNmmcVU-t",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
